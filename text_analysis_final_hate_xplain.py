# -*- coding: utf-8 -*-
"""text_analysis_final_hate_Xplain.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1NFBDS3-MJ26UEPICoLtqXcgiSMok0nua
"""

from google.colab import files
uploaded = files.upload()  # A file selection dialog will appear

import pandas as pd

# Use the filename of the uploaded file
data = pd.read_csv('final_hateXplain.csv')
print(data)

# View the first few rows
print(data.head())

# Check the column names and data types
print(data.info())

# Check for missing values
print(data.isnull().sum())

# View unique values in the target/emotion column (if present)
if 'sentiment' in data.columns or 'emotion' in data.columns:
    print(data['sentiment'].value_counts())

print(data.columns)

import re
import nltk
import pandas as pd

nltk.download('stopwords')
from nltk.corpus import stopwords

# Define stopwords
stop_words = set(stopwords.words('english'))

# Function to clean text
def preprocess_text(text):
    # Remove special characters and numbers
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    # Convert to lowercase
    text = text.lower()
    # Remove stopwords
    words = [word for word in text.split() if word not in stop_words]
    return ' '.join(words)

# Check if 'comment' column exists
if 'comment' in data.columns:
    # Apply preprocessing to the 'comment' column
    data['cleaned_text'] = data['comment'].apply(preprocess_text)
    # Display cleaned text
    print(data[['comment', 'cleaned_text']].head())
else:
    print("Column 'comment' does not exist in the DataFrame.")

from transformers import pipeline

# Load a pre-trained sentiment analysis pipeline with DistilBERT
sentiment_analyzer = pipeline("sentiment-analysis", model="distilbert-base-uncased-finetuned-sst-2-english")

# Apply DistilBERT sentiment analysis
data['sentiment'] = data['cleaned_text'].apply(lambda x: sentiment_analyzer(x)[0]['label'])

# View results
print(data[['cleaned_text', 'sentiment']].head())

import matplotlib.pyplot as plt
import seaborn as sns

# Visualize sentiment distribution
plt.figure(figsize=(8, 5))
sns.countplot(data=data, x='sentiment', order=data['sentiment'].value_counts().index)
plt.title("Sentiment Distribution")
plt.xlabel("Sentiment")
plt.ylabel("Count")
plt.show()

# Check if there's class imbalance
print(data['sentiment'].value_counts())

from sklearn.model_selection import train_test_split

# Assuming 'cleaned_text' is the text and 'sentiment' is the target
X = data['cleaned_text']
y = data['sentiment']

# Split the data into training and testing sets (80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Verify the split
print(f"Training set size: {len(X_train)}")
print(f"Test set size: {len(X_test)}")

from sklearn.feature_extraction.text import TfidfVectorizer

# Initialize the vectorizer
vectorizer = TfidfVectorizer(max_features=5000)

# Fit and transform the training data, and transform the test data
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

# Verify the shape of the transformed data
print(f"X_train_tfidf shape: {X_train_tfidf.shape}")
print(f"X_test_tfidf shape: {X_test_tfidf.shape}")

from sklearn.linear_model import LogisticRegression

# Initialize and train the model
model = LogisticRegression(max_iter=1000)
model.fit(X_train_tfidf, y_train)

# Check training accuracy
train_accuracy = model.score(X_train_tfidf, y_train)
print(f"Training Accuracy: {train_accuracy}")

# Evaluate the model on the test data
test_accuracy = model.score(X_test_tfidf, y_test)
print(f"Test Accuracy: {test_accuracy}")

from sklearn.metrics import classification_report, confusion_matrix

# Make predictions on the test data
y_pred = model.predict(X_test_tfidf)

# Print classification report
print(classification_report(y_test, y_pred))

# Confusion matrix to show how the model is performing
conf_matrix = confusion_matrix(y_test, y_pred)
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=model.classes_, yticklabels=model.classes_)
plt.title("Confusion Matrix")
plt.xlabel("Predicted Sentiment")
plt.ylabel("True Sentiment")
plt.show()

import joblib

# Save the trained model and vectorizer
joblib.dump(model, 'sentiment_model.pkl')
joblib.dump(vectorizer, 'tfidf_vectorizer.pkl')

from transformers import pipeline

# Load a pre-trained sentiment analysis pipeline
sentiment_analyzer = pipeline("sentiment-analysis")

# Example new text for prediction
new_text = ["I love this product! It's amazing."]

# Apply sentiment analysis
new_predictions = sentiment_analyzer(new_text)

# Print the predicted sentiment
for prediction in new_predictions:
    print(f"Predicted Sentiment: {prediction['label']} with score: {prediction['score']:.4f}")

